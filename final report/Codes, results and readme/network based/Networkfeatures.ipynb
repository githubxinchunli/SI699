{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "genuine_accounts_users = pd.read_csv('cresci-2017.csv/datasets_full.csv/genuine_accounts.csv/users.csv')\n",
    "genuine_accounts_tweets = pd.read_csv('cresci-2017.csv/datasets_full.csv/genuine_accounts.csv/tweets.csv')\n",
    "social_spambots_2_users = pd.read_csv('cresci-2017.csv/datasets_full.csv/social_spambots_2.csv/users.csv')\n",
    "social_spambots_2_tweets = pd.read_csv('cresci-2017.csv/datasets_full.csv/social_spambots_2.csv/tweets.csv')\n",
    "social_spambots_3_users = pd.read_csv('cresci-2017.csv/datasets_full.csv/social_spambots_2.csv/users.csv')\n",
    "social_spambots_3_tweets = pd.read_csv('cresci-2017.csv/datasets_full.csv/social_spambots_2.csv/tweets.csv')\n",
    "traditional_spambots_1_users = pd.read_csv('cresci-2017.csv/datasets_full.csv/traditional_spambots_1.csv/users.csv', low_memory=False)\n",
    "traditional_spambots_1_tweets = pd.read_csv('cresci-2017.csv/datasets_full.csv/traditional_spambots_1.csv/tweets.csv', low_memory=False)\n",
    "fake_followers_users=pd.read_csv('cresci-2017.csv/datasets_full.csv/fake_followers.csv/users.csv', low_memory=False)\n",
    "fake_followers_tweets=pd.read_csv('cresci-2017.csv/datasets_full.csv/fake_followers.csv/tweets.csv', low_memory=False)\n",
    "russian_troll_users = pd.read_csv('russian-troll-tweets/users.csv', low_memory=False)\n",
    "russian_troll_tweets = pd.read_csv('russian-troll-tweets/tweets.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "a=genuine_accounts_tweets.sample(n=1000, random_state=1)\n",
    "b=social_spambots_2_tweets.sample(n=1000, random_state=1)\n",
    "c=social_spambots_3_tweets.sample(n=1000, random_state=1)\n",
    "d=traditional_spambots_1_tweets.sample(n=1000, random_state=1)\n",
    "e=fake_followers_tweets.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a[['user_id', 'in_reply_to_user_id']]\n",
    "b=b[['user_id', 'in_reply_to_user_id']]\n",
    "c=c[['user_id', 'in_reply_to_user_id']]\n",
    "d=d[['user_id', 'in_reply_to_user_id']]\n",
    "e=e[['user_id', 'in_reply_to_user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['label']=int(0)\n",
    "b['label']=int(1)\n",
    "c['label']=int(1)\n",
    "d['label']=int(1)\n",
    "e['label']=int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_label=a[['user_id', 'label']].drop_duplicates()\n",
    "b_label=b[['user_id', 'label']].drop_duplicates()\n",
    "c_label=c[['user_id', 'label']].drop_duplicates()\n",
    "d_label=d[['user_id', 'label']].drop_duplicates()\n",
    "e_label=e[['user_id', 'label']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcde_label=pd.concat([a_label, b_label, c_label, d_label, e_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.groupby(['user_id', 'in_reply_to_user_id']).size().to_frame().reset_index('in_reply_to_user_id').rename(columns={0:'weight'})\n",
    "b=b.groupby(['user_id', 'in_reply_to_user_id']).size().to_frame().reset_index('in_reply_to_user_id').rename(columns={0:'weight'})\n",
    "c=c.groupby(['user_id', 'in_reply_to_user_id']).size().to_frame().reset_index('in_reply_to_user_id').rename(columns={0:'weight'})\n",
    "d=d.groupby(['user_id', 'in_reply_to_user_id']).size().to_frame().reset_index('in_reply_to_user_id').rename(columns={0:'weight'})\n",
    "e=e.groupby(['user_id', 'in_reply_to_user_id']).size().to_frame().reset_index('in_reply_to_user_id').rename(columns={0:'weight'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "DG = nx.DiGraph()\n",
    "DG.add_nodes_from(a.index)\n",
    "DG.add_nodes_from(b.index)\n",
    "DG.add_nodes_from(c.index)\n",
    "DG.add_nodes_from(d.index)\n",
    "DG.add_nodes_from(e.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "replyid_a=[]\n",
    "for i in range(len(a)):\n",
    "    tuple=(int(a.index[i]), int(a.iloc[i][0]),int(a.iloc[i][1]))\n",
    "    replyid_a.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "replyid_b=[]\n",
    "for i in range(len(b)):\n",
    "    tuple=(int(b.index[i]), int(b.iloc[i][0]),int(b.iloc[i][1]))\n",
    "    replyid_b.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "replyid_c=[]\n",
    "for i in range(len(c)):\n",
    "    tuple=(int(c.index[i]), int(c.iloc[i][0]),int(c.iloc[i][1]))\n",
    "    replyid_c.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "replyid_d=[]\n",
    "for i in range(len(d)):\n",
    "    tuple=(int(d.index[i]), int(d.iloc[i][0]),int(d.iloc[i][1]))\n",
    "    replyid_d.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "replyid_e=[]\n",
    "for i in range(len(e)):\n",
    "    tuple=(int(e.index[i]), int(e.iloc[i][0]),int(e.iloc[i][1]))\n",
    "    replyid_e.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.add_weighted_edges_from(replyid_a)\n",
    "DG.add_weighted_edges_from(replyid_b)\n",
    "DG.add_weighted_edges_from(replyid_c)\n",
    "DG.add_weighted_edges_from(replyid_d)\n",
    "DG.add_weighted_edges_from(replyid_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 32174\\nNumber of edges: 33091\\nAverage in degree:   1.0285\\nAverage out degree:   1.0285'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(DG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(DG, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits=nx.pagerank(DG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d={'user_id':list(pr.keys()), 'page_rank':list(pr.values())}\n",
    "pr_frame=pd.DataFrame(data=d)\n",
    "\n",
    "import numpy as np\n",
    "d={'user_id':list(hits.keys()), 'hits':list(hits.values())}\n",
    "hits_frame=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1=pd.merge(pr_frame, abcde_label, on = 'user_id')\n",
    "merged=pd.merge(merged, hits_frame, on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=merged[['user_id', 'page_rank', 'hits', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "merged=shuffle(merged)\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged.drop(columns='label'), merged.label, test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5700175422880653e-05"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['label']==0]['page_rank'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5700175422880653e-05"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['label']==1]['hits'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(penalty=\"l1\",random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9012597058855831"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lr_accuracy = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=5)\n",
    "np.mean(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9582517874205132"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(max_depth=5, criterion='entropy',\n",
    "                                   random_state=0).fit(X_train, y_train)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lr_accuracy = cross_val_score(rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
    "np.mean(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96322032222991"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdb_model = GradientBoostingClassifier(learning_rate=1.0, max_depth=3, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lr_accuracy = cross_val_score(gdb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
    "np.mean(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/xinchunli/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9012597058855831"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(gamma='auto', max_iter=100).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lr_accuracy = cross_val_score(svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
    "np.mean(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
